{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502a8630-d229-43bd-9ba7-db6e967e0155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826aa15a-cbc7-4e60-a2c4-743c70bbd315",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Gym Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5883a02a-ade3-4ada-8006-43e0e4dfdbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_FIELD_PARAMS = [0, 0, 1.0]     # Vx, Vy, K\n",
    "DEFAULT_ENV_PARAMS = [1.0, 1.0, 0.1]  # dx, dy, dt\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# SPATIAL-TEMPORAL DIFFUSION FIELD\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "class SpatialTemporalDiffusionField():\n",
    "    def __init__(self, pos=(50,50), map_size=100, field_size=40, field_max=25, n_timesteps=None, field_params=DEFAULT_FIELD_PARAMS, env_params=DEFAULT_ENV_PARAMS):\n",
    "        # initialize field params\n",
    "        self.dx, self.dy, self.dt = env_params\n",
    "        self.vx, self.vy, self.k = field_params\n",
    "        self.field_size, self.field_max, self.map_size = field_size, field_max, map_size\n",
    "        self.snapshots = None\n",
    "        # generate field\n",
    "        field_hsize = field_size // 2\n",
    "        self.gaussian_field = self.generate_multivariate_gaussian_field(N=field_size)\n",
    "        self.field = np.zeros((map_size, map_size))\n",
    "        self.padded_field = np.zeros((3*map_size, 3*map_size))\n",
    "        x_start, x_end = map_size+pos[0]-field_hsize, map_size+pos[0]+field_hsize\n",
    "        y_start, y_end = map_size+pos[1]-field_hsize, map_size+pos[1]+field_hsize\n",
    "        self.padded_field[y_start:y_end, x_start:x_end]=self.gaussian_field\n",
    "        self.field = self.padded_field[map_size:map_size*2,map_size:map_size*2]\n",
    "        self.field = (self.field - np.min(self.field)) / (np.max(self.field)-np.min(self.field)) * self.field_max\n",
    "        # generate snapshots\n",
    "        if (n_timesteps is not None) and (n_timesteps > 0):\n",
    "            self.snapshots = np.zeros((n_timesteps,map_size,map_size))\n",
    "            self.snapshots[0] = self.field\n",
    "            for i in range(1, n_timesteps):\n",
    "                self.snapshots[i] = self.update_diffusion_field(self.snapshots[i-1])        \n",
    "    \n",
    "    def generate_multivariate_gaussian_field(self, N=40, mu=np.array([0.,0.]), sigma=np.array([[1.,0.],[0.,1.]])):\n",
    "        X = np.linspace(-3.0, 3.0, N)\n",
    "        Y = np.linspace(-3.0, 3.0, N)\n",
    "        X, Y = np.meshgrid(X, Y)\n",
    "        pos = np.empty(X.shape + (2,))\n",
    "        pos[:,:,0] = X\n",
    "        pos[:,:,1] = Y\n",
    "        n = mu.shape[0]\n",
    "        sigma_det, sigma_inv = np.linalg.det(sigma), np.linalg.inv(sigma)\n",
    "        N = np.sqrt((2*np.pi)**n * sigma_det)\n",
    "        fac = np.einsum('...k,kl,...l->...', pos-mu, sigma_inv, pos-mu)\n",
    "        return np.exp(-fac / 2) / N\n",
    "    \n",
    "    def update_diffusion_field(self, field):\n",
    "        updated_u = field.copy()\n",
    "        u_k = field.copy()\n",
    "        for i in range(1, field.shape[0] - 1):\n",
    "            for j in range(1, field.shape[1] - 1):\n",
    "                updated_u[j, i] = u_k[j, i] + self.k * (self.dt / self.dx ** 2) * \\\n",
    "                    ((u_k[j + 1, i] + u_k[j - 1, i] +\n",
    "                      u_k[j, i + 1] + u_k[j, i - 1] - 4 * u_k[j, i])) + \\\n",
    "                    self.vx * (self.dt / self.dx) * ((u_k[j + 1, i] - u_k[j, i])) + self.vy * (self.dt / self.dy) * \\\n",
    "                    (u_k[j, i + 1] - u_k[j, i])\n",
    "        return updated_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc79768c-af4b-4450-946f-82902c284a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# SPATIAL-TEMPORAL DIFFUSION ENVIRONMENT\n",
    "# (consists of multiple diffusion fields)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "class SpatialTemporalDiffusionEnvironment():\n",
    "    def __init__(self, name, configs=[], env_params=DEFAULT_ENV_PARAMS, size=100, use_snapshots=True, n_timesteps=300):\n",
    "        self.name = name\n",
    "        self.field_size = size\n",
    "        self.configs = configs\n",
    "        self.dx, self.dy, self.dt = env_params\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.fields=[]\n",
    "        self.timestep = 0\n",
    "        for idx, config in enumerate(configs):\n",
    "            self.fields.append(SpatialTemporalDiffusionField(pos=config['pos'], field_size=config['size'], field_params=config['params'], \\\n",
    "                    env_params=env_params, map_size=size, n_timesteps=n_timesteps if use_snapshots else None))\n",
    "        self.set_timestep()\n",
    "    \n",
    "    def set_timestep(self, t=0):\n",
    "        self.isolated_field_states = np.array([self.fields[i].snapshots[t] for i in range(len(self.fields))])\n",
    "        self.env_field = np.sum(self.isolated_field_states, axis=0)\n",
    "        self.timestep = t\n",
    "        \n",
    "    def step(self):\n",
    "        if self.timestep < self.n_timesteps:\n",
    "            self.set_timestep(self.timestep + 1)\n",
    "        \n",
    "    def get_single_field(self, idx=0):\n",
    "        if (idx>=0) and (idx<len(self.fields)):\n",
    "            return self.isolated_field_states[idx]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def compute_gradient(self, pos=[50,50]):\n",
    "        dz_dx = (self.env_field[pos[1], pos[0]+1] -\n",
    "                 self.env_field[pos[1], pos[0]-1]) / (2 * self.dx)\n",
    "        dz_dy = (self.env_field[pos[1]+1, pos[0]] -\n",
    "                 self.env_field[pos[1]-1, pos[0]]) / (2 * self.dy)\n",
    "        return np.array([dz_dx, dz_dy])\n",
    "    \n",
    "    def get_concentration(self, pos=[50,50]):\n",
    "        return self.env_field[pos[1],pos[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39447240-2418-46ad-a9d9-b22a42d5d1db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# SPATIAL-TEMPORAL DIFFUSION FIELD GYM WRAPPER\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "ACTION_MAP = {0:\"left\",1:\"right\",2:\"up\",3:\"down\",4:\"stay\",5:\"up-left\",6:\"up-right\",7:\"down-left\",8:\"down-right\"}\n",
    "ACTIONS = [\"left\", \"right\", \"up\", \"down\", \"stay\", \"up-left\", \"up-right\", \"down-left\", \"down-right\"]\n",
    "ACTION_OFFSET = np.array([[-1,0],[1,0],[0,-1],[0,1],[0,0],[-1,-1],[1,-1],[-1,1],[1,1]])\n",
    "# DEFAULT_START_POSITIONS = [[50,20],[50,80],[20,50],[80,50],[25,25],[75,75]]\n",
    "\n",
    "class SpatialTemporalDiffusionEnvGymWrapper(gym.Env):\n",
    "    \n",
    "    def __init__(self, envs=[], max_steps=299, vs_hsize=5, spawn_pos_range=[1.2,1.5], keep_env_on_reset=False):\n",
    "        metadata = {'render.modes': ['human']}\n",
    "        super(SpatialTemporalDiffusionEnvGymWrapper, self).__init__()\n",
    "        \n",
    "        self.envs = envs\n",
    "        self.env = random.choice(envs)\n",
    "        self.keep_env_on_reset = keep_env_on_reset\n",
    "        \n",
    "        assert self.env.n_timesteps >= max_steps, f\"max numsteps should not exceed max snapshots of this env\"\n",
    "                    \n",
    "        self.max_steps = max_steps\n",
    "        self.vs_hsize = vs_hsize\n",
    "        self.spawn_pos_range = spawn_pos_range\n",
    "        \n",
    "        # Agent Field related params/variables\n",
    "        self.agent_position = None\n",
    "        self.num_steps = 0\n",
    "\n",
    "        # Action Space\n",
    "        self.action_space_map = ACTION_MAP\n",
    "        self.actions = ACTIONS\n",
    "        self.action_offsets = ACTION_OFFSET\n",
    "        self.action_space = gym.spaces.Discrete(9)\n",
    "\n",
    "        # Observation Space\n",
    "        low = np.array([0.0, -100.0, -100.0])\n",
    "        high = np.array([25.0, 100.0, 100.0])\n",
    "        self.observation_space = gym.spaces.Box(low, high, dtype=np.float64)\n",
    "        \n",
    "    def step(self, action_id):\n",
    "        # Ensure action is a valid action and exists in Agent's action space\n",
    "        assert self.action_space.contains(action_id), \"Action %r (%s) is invalid!\" % (action_id, type(action_id))        \n",
    "        action = self.action_space_map[action_id]\n",
    "\n",
    "        # Get the next state\n",
    "        (hit_wall, next_position) = self.get_next_position(action_id)\n",
    "        if (hit_wall):\n",
    "            # Stay at the same place if hitting boundary\n",
    "            next_position = self.agent_position\n",
    "\n",
    "        # Update field state\n",
    "        self.env.step()\n",
    "        \n",
    "        # Update number of steps\n",
    "        self.num_steps += 1\n",
    "\n",
    "        # Update agent variables\n",
    "        self.agent_position = next_position\n",
    "\n",
    "        # Get concentration\n",
    "        self.concentration = self.env.get_concentration(self.agent_position)\n",
    "        self.gradients = self.env.compute_gradient(self.agent_position)        \n",
    "        next_state = [self.concentration, self.gradients[0], self.gradients[1]]\n",
    "        \n",
    "        # Check for termination criteria\n",
    "        done = self.num_steps >= self.max_steps\n",
    "        reward = self.calculate_reward(next_position, self.gradients)\n",
    "\n",
    "        # Get any observations\n",
    "        observations = {\"location\": next_position}\n",
    "        \n",
    "        return (next_state, reward, done, observations)\n",
    "    \n",
    "    def get_random_start_position(self):\n",
    "        in_range = (self.env.env_field>=self.spawn_pos_range[0]) & (self.env.env_field<=self.spawn_pos_range[1])\n",
    "        return np.flip(random.choice(np.transpose(np.nonzero(in_range))))\n",
    "    \n",
    "    def reset(self, pos=None, env_id=None):\n",
    "        if env_id is not None:\n",
    "            self.env = self.envs[env_id]\n",
    "        elif not self.keep_env_on_reset:\n",
    "            self.env = random.choice(self.envs)\n",
    "        assert self.env.n_timesteps >= self.max_steps, f\"max numsteps should not exceed max snapshots of this env\"\n",
    "        self.num_steps = 0\n",
    "        self.env.set_timestep()\n",
    "        self.agent_position = pos if pos is not None else self.get_random_start_position()\n",
    "        self.concentration = self.env.get_concentration(self.agent_position)\n",
    "        self.gradients = self.env.compute_gradient(self.agent_position)\n",
    "        observations = {\"location\": self.agent_position}\n",
    "        next_state = [self.concentration, self.gradients[0], self.gradients[1]]\n",
    "        return next_state\n",
    "\n",
    "    def get_next_position(self, action_id):\n",
    "        # Create a deepcopy of current state\n",
    "        next_state = copy.deepcopy(self.agent_position)\n",
    "        next_state = np.add(next_state, ACTION_OFFSET[action_id])\n",
    "\n",
    "        # Check for collisions\n",
    "        hit_wall = False\n",
    "        if ((next_state[0] < (0 + self.vs_hsize) or next_state[0] >= (self.env.field_size - self.vs_hsize)) or\n",
    "            ((next_state[1] < (0 + self.vs_hsize) or next_state[1] >= (self.env.field_size - self.vs_hsize)))):\n",
    "            hit_wall = True\n",
    "\n",
    "        return (hit_wall, next_state)\n",
    "    \n",
    "    def get_viewscope_state(self, next_state):\n",
    "        vs_min_row, vs_max_row = next_state[0] - self.vs_hsize, next_state[0] + self.vs_hsize + 1\n",
    "        vs_min_col, vs_max_col = next_state[1] - self.vs_hsize, next_state[1] + self.vs_hsize + 1\n",
    "        vs_state = self.env.env_field[vs_min_col:vs_max_col, vs_min_row:vs_max_row]\n",
    "        return vs_state\n",
    "\n",
    "    def calculate_reward(self, next_state, gradients):\n",
    "        reward_from_vs = 1e-2 * np.sum(self.get_viewscope_state(next_state))\n",
    "        if reward_from_vs < 10:\n",
    "            return reward_from_vs\n",
    "        else:\n",
    "            sum_sq_grad = (gradients[0] ** 2) + (gradients[1] ** 2)\n",
    "            reward_from_grad = 20 * np.exp(-5 * sum_sq_grad)\n",
    "            return reward_from_vs + reward_from_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f4c86-cbc8-4715-8e48-b02bd1c17d11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Exploration Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c617b7-1f47-4b96-8ca7-c49e35e1066c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0205b8-5407-4f07-9e2d-6feea752ab37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseHandler():\n",
    "    def __init__(self, field_size=100, position=(50,50)):\n",
    "        pass\n",
    "    def get_next_action(self, state, params):\n",
    "        pass\n",
    "    def reset(self, source_found=None, params={}):\n",
    "        pass\n",
    "    def get_action_by_dest(self, pos, dest):\n",
    "        if (pos == dest).all():\n",
    "            return 4, True\n",
    "        dx = dest[0] - pos[0]\n",
    "        dy = dest[1] - pos[1]\n",
    "        steps = abs(dx) if abs(dx) > abs(dy) else abs(dy)\n",
    "        offset = np.array([int(dx/steps), int(dy/steps)])\n",
    "        action_id = np.where((ACTION_OFFSET==offset).all(1))[0][0]\n",
    "        dest_reached = pos[0]+offset[0]==dest[0] and pos[1]+offset[1]==dest[1]\n",
    "        return action_id, dest_reached\n",
    "    def bounded_vec(self, raw_vec, field_size=100, padding=0):\n",
    "        return np.array([max(min(raw_vec[0], field_size-padding-2), padding), max(min(raw_vec[1], field_size-padding-2), padding)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48987a7e-6e76-4bd1-b1d0-c914d07a4465",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Cluster-based Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f69febb4-5a19-47d2-9a42-eb0f748af9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClusterBasedExplorationHandler(BaseHandler):\n",
    "    def __init__(self, pos=[50,50], field_size=100, vs_hsize=5):\n",
    "        self.pos = np.array(pos)\n",
    "        self.field_size = field_size\n",
    "        self.field = np.zeros((self.field_size,self.field_size))\n",
    "        self.field_mask = np.zeros((self.field_size,self.field_size))\n",
    "        self.field_clusters = np.zeros((self.field_size,self.field_size))\n",
    "        self.generate_clustered_field()\n",
    "        self.nearest_centroid_idx = np.argmin(np.linalg.norm(self.centroids - self.pos, axis=1))\n",
    "        self.target_centroid = np.round(self.centroids[self.nearest_centroid_idx])\n",
    "        self.dest_reached = False\n",
    "        \n",
    "    def generate_clustered_field(self, k=6):\n",
    "        self.indices = np.argwhere(self.field_mask == 0)\n",
    "        self.kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto').fit(self.indices)\n",
    "        self.field_clusters = np.zeros((self.field_size,self.field_size))\n",
    "        for idx, fieldIdx in enumerate(self.indices):            \n",
    "            self.field_clusters[fieldIdx[0],fieldIdx[1]] = self.kmeans.labels_[idx]+1\n",
    "        self.centroids = self.kmeans.cluster_centers_[:,::-1]\n",
    "        self.labels = np.array(list(range(len(self.centroids))))\n",
    "        \n",
    "    def get_next_action(self, position):\n",
    "        self.pos = np.array(position)\n",
    "        if self.dest_reached:\n",
    "            self.update_target_centroid()\n",
    "        if self.target_centroid is None:\n",
    "            return 4, False\n",
    "        else:\n",
    "            action_id, dest_reached = self.get_action_by_dest(self.pos, self.target_centroid)\n",
    "            self.dest_reached = dest_reached\n",
    "            return action_id, dest_reached\n",
    "            \n",
    "    def update_target_centroid(self):\n",
    "        if len(self.centroids) > 1:\n",
    "            self.field_mask[self.field_clusters==(self.labels[self.nearest_centroid_idx]+1)] = 1\n",
    "            self.centroids = np.delete(self.centroids, self.nearest_centroid_idx, axis=0)\n",
    "            self.labels =  np.delete(self.labels, self.nearest_centroid_idx, axis=0)\n",
    "            if len(self.centroids) > 0:\n",
    "                self.nearest_centroid_idx = np.argmin(np.linalg.norm(self.centroids - self.pos, axis=1))\n",
    "                self.target_centroid = np.round(self.centroids[self.nearest_centroid_idx])\n",
    "        else:\n",
    "            self.nearest_centroid_idx = None\n",
    "            self.target_centroid = None\n",
    "                \n",
    "    def reset(self, field_mask=None):\n",
    "        if field_mask is not None:\n",
    "            self.field_mask = field_mask\n",
    "        unvisited_size = self.field_size**2 - np.count_nonzero(self.field_mask)\n",
    "        estimated_k = unvisited_size / self.source_size**2\n",
    "        if estimated_k > 0.25 and (self.field_mask == 0).any():\n",
    "            self.generate_clustered_field(k=np.maximum(2, int(estimated_k)))\n",
    "            self.nearest_centroid_idx = np.argmin(np.linalg.norm(self.centroids - self.pos, axis=1))\n",
    "            self.target_centroid = np.round(self.centroids[self.nearest_centroid_idx])\n",
    "        else:\n",
    "            self.indices = np.argwhere(self.field_mask == 0)\n",
    "            self.target_centroid = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6630a-2fbf-4caa-9bec-dd808513bda0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Lawn Mowing Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44e3fb7-5332-4d91-aa42-39929d3c55ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAWNMOWING_START_PRESET = [[0,0],[0,1],[1,0],[1,1]]\n",
    "LAWNMOWING_DIR_PRESET = [[1,1],[1,-1],[-1,1],[-1,-1]]\n",
    "MAIN_AXIS, CROSS_AXIS = 0, 1\n",
    "\n",
    "class LawnMowingExplorationHandler(BaseHandler):\n",
    "    def __init__(self, field_size=100, vs_hsize=5):\n",
    "        self.field_size = field_size\n",
    "        self.vs_hsize = vs_hsize\n",
    "        self.main_axis, self.cross_axis = MAIN_AXIS, CROSS_AXIS\n",
    "        \n",
    "    def reset(self, position=[50,50]):\n",
    "        self.target_reached = False\n",
    "        self.target = None        \n",
    "        self.start_position, self.start_idx = self.get_start_position(position)\n",
    "        self.main_direction, self.cross_direction = LAWNMOWING_DIR_PRESET[self.start_idx][0], LAWNMOWING_DIR_PRESET[self.start_idx][1]\n",
    "        self.is_main_direction = True\n",
    "        self.start_position_visited = False\n",
    "        \n",
    "    def get_start_position(self, position):\n",
    "        curr_position = np.array(position)\n",
    "        start_positions = np.array(LAWNMOWING_START_PRESET) * self.field_size\n",
    "        distances = np.linalg.norm(start_positions - curr_position)\n",
    "        nearest_idx = np.argmin(distances)\n",
    "        return self.bounded_vec(start_positions[nearest_idx], field_size=self.field_size, padding=self.vs_hsize), nearest_idx\n",
    "        \n",
    "    def get_next_action(self, position=[50,50]):\n",
    "        self.pos = np.array(position)\n",
    "        if (self.target is None) or self.dest_reached:            \n",
    "            self.target = self.get_target_position(position)\n",
    "        action_id, self.dest_reached = self.get_action_by_dest(self.pos, self.target)\n",
    "        return action_id, self.dest_reached\n",
    "                \n",
    "    def get_target_position(self, position):\n",
    "        self.start_position_visited = self.start_position_visited or tuple(position) == tuple(self.start_position)\n",
    "        if not self.start_position_visited:\n",
    "            return self.start_position\n",
    "        else:\n",
    "            target = np.array(position)\n",
    "            if self.is_main_direction:\n",
    "                target[self.main_axis] += self.main_direction * self.field_size\n",
    "                self.main_direction = -self.main_direction # main direction is toogled after being used\n",
    "                self.is_main_direction = False\n",
    "            else:\n",
    "                target[self.cross_axis] += self.cross_direction * self.half_scope_size * 2\n",
    "                self.is_main_direction = True\n",
    "            target = self.bounded_vec(target, field_size=self.field_size, padding=self.vs_hsize)\n",
    "            return target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46835089-1268-4d3f-9719-4ee9f7f9b4c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Random Walking Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed58fb8-107d-481a-a20f-7a06f389207b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomExplorationHandler(BaseHandler):\n",
    "    def get_next_action(self, position):\n",
    "        return np.random.randint(0,9), False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e1650-1aaa-4921-bf74-67ab18eb35f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Dummy Source-heading Component**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd87176f-573d-426f-912e-6c8c5d8927f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientSourceHeadingHandler(BaseHandler):\n",
    "    def __init__(self, field_size=100, vs_hsize=5):\n",
    "        self.field_size = field_size\n",
    "        self.vs_hsize = vs_hsize\n",
    "    def get_next_action(self, state = None):\n",
    "        assert state is not None, \"no state available\"\n",
    "        grad_vec = np.array([state[1], state[2]])\n",
    "        grad_vec_k = self.k * grad_vec / np.linalg.norm(grad_vec)\n",
    "        position = np.array(params['location'])\n",
    "        target_position = self.bounded_vec(position + grad_vec_k, field_size=self.field_size).round()\n",
    "        action_id, dest_reached = self.get_action_by_dest(position, target_position)\n",
    "        return action_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef416e-584d-4c54-9ef0-132295028313",
   "metadata": {},
   "source": [
    "## **Testing Cluster-based Exploration Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7bc357-128b-41da-b334-8fdb50740459",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Environments\n",
    "selected_maps = ['1-src-2','2-src-1','2-src-3','2-src-5','3-src-4','4-src-2',]\n",
    "envs = []\n",
    "for name in selected_maps:\n",
    "    with open(f'./data/envs/{name}.dat', 'rb') as handle:\n",
    "        envs.append(pickle.load(handle))\n",
    "\n",
    "exploration_handler = ClusterBasedExplorationHandler()\n",
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60afaa-8d95-4265-bff0-0560264a7e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapper = SpatialTemporalDiffusionEnvGymWrapper(envs=envs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "054e2bd8-8234-49a3-9264-819119a972f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (882769628.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    plot_env_subplot(env, axes[idx//3,idx%3], name)reset\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "fig, axes = plt.subplots(len(selected_maps)//3, 3, figsize=(15, 10))\n",
    "fig.suptitle('Cluster-based Exploration & Gradient-based Source Heading')\n",
    "for idx, name in enumerate(selected_maps):\n",
    "    state, obsr  = env_wrapper.reset(pos=[90,10], env_id=idx)\n",
    "    steps = 0\n",
    "    z_thresh = 5\n",
    "    exploration_handler = ClusterBasedExplorationHandler()\n",
    "    src_heading_handler = GradientSourceHeadingHandler()\n",
    "    explore_mode = True\n",
    "    new_target_reached = True\n",
    "    while True:\n",
    "        if explore_mode:\n",
    "            action_id, dest_reached = exploration_handler.get_next_action(state, obsr)\n",
    "            new_target_reached = new_target_reached or dest_reached \n",
    "            state, reward, done, obsr = env_wrapper.step(action_id)\n",
    "            if state[0] > z_thresh and new_target_reached:\n",
    "                explore_mode = False \n",
    "        else:\n",
    "            action_id = src_heading_handler.get_next_action(state, obsr)    \n",
    "            state, reward, done, obsr = env_wrapper.step(action_id)\n",
    "            if \"source_found\" in obsr.keys():\n",
    "                explore_mode = True\n",
    "                new_target_reached = False\n",
    "                exploration_handler.reset(field_mask=env_wrapper.env.isolated_field_states[])\n",
    "        if done:\n",
    "            plot_env_subplot(env_wrapper.env, axes[idx//3,idx%3], name)\n",
    "            # plt.imshow(env.agent_field.visited_field)\n",
    "            break\n",
    "        steps += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18f65b-2658-4236-837f-07c5d3654604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
